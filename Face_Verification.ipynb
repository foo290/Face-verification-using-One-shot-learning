{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn import MTCNN\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the detector which will detect the face in Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('Models/facenet_keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path where the face embedding will be saved of the registered user\n",
    "face_print_registry_database = 'Registry_database/Face Print/' \n",
    "\n",
    "\n",
    "# path where the images will be stored temporarily if you are using webcam of your system.\n",
    "# You can also save your target images in this folder if you are not using a webcam\n",
    "# Customize the folder according to your system. \n",
    "temp_face_capture_path = 'C:/Tensorflow_GPU/temp_cap/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marker_function(features,image,x1,x2,y1,y2):\n",
    "    \n",
    "    \"\"\" This function just mark the face and its components with a green line \"\"\"\n",
    "    \n",
    "    detected_faces = features\n",
    "        \n",
    "    mask_clr = 'lawngreen'\n",
    "    mask_width = 3\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.rectangle(((x1,y1), (x2,y2)), outline=mask_clr,width=mask_width)\n",
    "\n",
    "\n",
    "    leye = detected_faces['keypoints']['left_eye']\n",
    "    reye = detected_faces['keypoints']['right_eye']\n",
    "    nose = detected_faces['keypoints']['nose']\n",
    "    lmouth = detected_faces['keypoints']['mouth_left']\n",
    "    rmouth = detected_faces['keypoints']['mouth_right']\n",
    "\n",
    "    # left upper corner to left eye \n",
    "    draw.line((x1,y1)+leye, fill=mask_clr, width=mask_width)\n",
    "    # right bottom corner to right eye\n",
    "    draw.line((x2,y2)+reye, fill=mask_clr, width=mask_width)\n",
    "    # left bottom corner to left mouth\n",
    "    draw.line((x1,y2)+lmouth, fill=mask_clr, width=mask_width)\n",
    "    # right bottom corner to right  mouth\n",
    "    draw.line((x2,y2)+rmouth, fill=mask_clr, width=mask_width)\n",
    "    # right upper corner to right mouth\n",
    "    draw.line((x2,y1)+reye, fill=mask_clr, width=mask_width)\n",
    "    # left bottom corner to left eye\n",
    "    draw.line((x1,y2)+leye, fill=mask_clr, width=mask_width)\n",
    "    # left upper corner to left mouth\n",
    "    draw.line((x1,y1)+lmouth, fill=mask_clr, width=mask_width)\n",
    "    # right uupper corner to right mouth\n",
    "    draw.line((x2,y1)+rmouth, fill=mask_clr, width=mask_width)\n",
    "    # right upper corner to left eye\n",
    "    draw.line((x2,y1)+leye, fill=mask_clr, width=mask_width)\n",
    "    # left upeer corner to right eye\n",
    "    draw.line((x1,y1)+reye, fill=mask_clr, width=mask_width)\n",
    "    # left bottom corner to right mouth\n",
    "    draw.line((x1,y2)+rmouth, fill=mask_clr, width=mask_width)\n",
    "    # right bottom corner to left mouth\n",
    "    draw.line((x2,y2)+lmouth, fill=mask_clr, width=mask_width)\n",
    "    # right middle divisor to right eye and mouth\n",
    "    draw.line((x2,(y1+y2)//2)+reye, fill=mask_clr, width=mask_width)\n",
    "    draw.line((x2,(y1+y2)//2)+rmouth, fill=mask_clr, width=mask_width)\n",
    "    # left middle divisor to left mouth and eye \n",
    "    draw.line((x1,(y1+y2)//2)+leye, fill=mask_clr, width=mask_width)\n",
    "    draw.line((x1,(y1+y2)//2)+lmouth, fill=mask_clr, width=mask_width)\n",
    "\n",
    "\n",
    "    # top middle diviro to bot eyes\n",
    "    draw.line(((x1+x2)//2,y1)+reye, fill=mask_clr, width=mask_width)\n",
    "    draw.line(((x1+x2)//2,y1)+leye, fill=mask_clr, width=mask_width)\n",
    "    # bottom middle divisor for bot mouths\n",
    "    draw.line(((x1+x2)//2,y2)+rmouth, fill=mask_clr, width=mask_width)\n",
    "    draw.line(((x1+x2)//2,y2)+lmouth, fill=mask_clr, width=mask_width)\n",
    "    # middle star symbol\n",
    "    draw.line(((x1+x2)//2,y1)+nose, fill=mask_clr, width=mask_width)\n",
    "    draw.line(nose+(x2,y2), fill=mask_clr, width=mask_width)\n",
    "    draw.line(nose+(x1,y2), fill=mask_clr, width=mask_width)\n",
    "\n",
    "\n",
    "\n",
    "    draw.line(leye+reye,fill=mask_clr, width=mask_width)\n",
    "\n",
    "    draw.line(leye+nose,fill=mask_clr, width=mask_width)\n",
    "\n",
    "    draw.line(reye+nose, fill=mask_clr, width=mask_width)\n",
    "\n",
    "\n",
    "\n",
    "    draw.line(nose+lmouth, fill=mask_clr, width=mask_width)\n",
    "\n",
    "    draw.line(nose+rmouth, fill=mask_clr, width=mask_width)\n",
    "\n",
    "    draw.line(lmouth+rmouth, fill=mask_clr, width=mask_width)\n",
    "\n",
    "\n",
    "    eye_diffrence = reye[0]-leye[0]\n",
    "#         print(eye_diffrence)\n",
    "\n",
    "    image.save('marked.jpeg', \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face(path,resize_scale=(160,160)):\n",
    "    \n",
    "    \"\"\" \n",
    "    This function is used to extract the face of 160x160 from the given image \n",
    "    \n",
    "    Input : image directory path as input\n",
    "    Returns : A tuple containing list of faces found, the original image.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    face_list=list()\n",
    "    \n",
    "    image = Image.open(path)\n",
    "    image = image.convert('RGB')\n",
    "        \n",
    "    pixels = np.asarray(image)\n",
    "#     print(pixels.shape)\n",
    "\n",
    "    faces_detected = detector.detect_faces(pixels)\n",
    "\n",
    "    for detected_faces in faces_detected:\n",
    "        x1, y1, width, height = detected_faces['box']\n",
    "        components = detected_faces\n",
    "        x1,y1 = abs(x1),abs(y1)\n",
    "\n",
    "        x2, y2 = x1+width, y1+height\n",
    "\n",
    "        final_face = pixels[y1:y2,x1:x2]\n",
    "        \n",
    "#         marker_function(detected_faces,image,x1,x2,y1,y2)\n",
    "        marker_function(detected_faces,image,x1,x2,y1,y2)\n",
    "\n",
    "        \n",
    "        pic = Image.fromarray(final_face)        \n",
    "        pic = pic.resize(resize_scale)\n",
    "        \n",
    "        face_array = np.asarray(pic)\n",
    "#         print(f'Extracted : {face_array.shape}')\n",
    "        \n",
    "        face_list.append(face_array)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "    return face_list,image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face_embeddings(face_pixels):\n",
    "    \n",
    "    \"\"\" This function takes faces extracted by get_face() and return a vector of 128 numbers known as Face Embeddings \"\"\"\n",
    "    \n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "    \n",
    "    mean, std = face_pixels.mean(), face_pixels.std()\n",
    "    face_pixels = (face_pixels - mean) / std\n",
    "\n",
    "    samples = np.expand_dims(face_pixels, axis=0)\n",
    "    yhat = model.predict(samples)\n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_frame():\n",
    "    \n",
    "    \"\"\" Used to capture image from web cam \"\"\"\n",
    "    \n",
    "    file_name = 'tempCapture'\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    \n",
    "    for i in range(2):\n",
    "        ret, frame = camera.read()\n",
    "        if ret:\n",
    "            cv2.imwrite(f'C:/Tensorflow_GPU/temp_cap/{file_name}_{i}.png',frame)\n",
    "        else:\n",
    "            return 0\n",
    "    camera.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_face(user_name):\n",
    "    \n",
    "    \"\"\" Saves the face embeddings into directory for comparision \"\"\"\n",
    "    \n",
    "    registry_raw_img = os.listdir(temp_face_capture_path)[0]\n",
    "    pixels_extracted, pixels_img = get_face(temp_face_capture_path+registry_raw_img) \n",
    "    if pixels_extracted:\n",
    "        features_extracted = get_face_embeddings(pixels_extracted[0])\n",
    "        if len(features_extracted):\n",
    "            np.savez_compressed(f'{face_print_registry_database}{user_name}.npz',features_extracted)\n",
    "        else:\n",
    "            return 500 # Cannot extract the features\n",
    "    else:\n",
    "        return 404 # face not found\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_user():\n",
    "    \n",
    "    \"\"\" Loads the saved faces from directory \"\"\"\n",
    "    \n",
    "    saved_faces = []\n",
    "    saved_faces_names = []\n",
    "    \n",
    "    embeddings_list = os.listdir(face_print_registry_database)\n",
    "    if embeddings_list:\n",
    "        for saved_compressed in embeddings_list:\n",
    "            loaded_embeddings = np.load(face_print_registry_database+saved_compressed)['arr_0']\n",
    "            saved_faces.append(loaded_embeddings)\n",
    "            saved_faces_names.append(saved_compressed.split('.')[0])\n",
    "\n",
    "        return saved_faces,saved_faces_names\n",
    "    else:\n",
    "        return 0,0,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_threshold = 10 # The threshold used to estimate the similarity \n",
    "\n",
    "def verify(saved_embeddings,saved_username):\n",
    "    \n",
    "    '''\n",
    "    Main function\n",
    "    \n",
    "    Work : \n",
    "        Extract the face embeddings of the given face\n",
    "        compare those embaddings with the saved ones.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if saved_embeddings:\n",
    "\n",
    "        for captured_faces in os.listdir('C:/Tensorflow_GPU/temp_cap/'):\n",
    "            target_face, target_img = get_face('C:/Tensorflow_GPU/temp_cap/'+captured_faces)\n",
    "            if target_face:\n",
    "                for faces in target_face:\n",
    "                    target_face_embeddings = get_face_embeddings(faces)\n",
    "                    \n",
    "                    for every_face, name in zip(saved_embeddings,saved_username):\n",
    "#                         print(every_face.shape,target_face_embeddings.shape)\n",
    "                        \n",
    "                        dist = np.linalg.norm(every_face-target_face_embeddings) # matching the image\n",
    "\n",
    "                        if dist<feature_threshold:\n",
    "                            print(f'Face Recognised as : {name}, Authentication Successfull | Vector Distance: {dist} | PIC : {captured_faces}')\n",
    "                            return 1\n",
    "                        else:\n",
    "                            print(f'Face Not Recognised... | Vector Distance: {dist} | PIC : {captured_faces}')\n",
    "\n",
    "            else:\n",
    "                print('No face detected in the input image...\\nTry keping ur face in center and straight.')\n",
    "                return 404 # no face detected\n",
    "    else:\n",
    "        return 501 # no previous registed user found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Registering user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "These two function are only called when we have to register a face.\n",
    "comment these two once you setup the face.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "capture_frame()\n",
    "register_face('Name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function loads the saved faces and unpack'em \"\"\"\n",
    "\n",
    "saved_embeddings,saved_username= load_saved_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Thses are the main function that should be called in order to compare the given face with the saved one. '''\n",
    "\n",
    "capture_frame() \n",
    "\n",
    "verify(saved_embeddings,saved_username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order of calling functions must be preserved"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
